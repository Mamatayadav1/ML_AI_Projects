{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Method 1 : Using `Pipeline`"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "from transformers import pipeline\n",
    "\n",
    "ppl = pipeline(task=\"question-answering\", model=\"bert-large-uncased-whole-word-masking-finetuned-squad\")\n",
    "\n",
    "question = \"What is Jersey Act ?\"\n",
    "context = '''\n",
    "The Jersey Act was introduced to prevent the registration of most American-bred Thoroughbred horses in the British General Stud Book. It had its roots in the desire of British horse breeders to halt the influx of American-bred racehorses of possibly impure bloodlines during the early 20th century. Many American-bred horses were exported to Europe to race and retire to a breeding career after a number of U.S. states banned gambling, which depressed Thoroughbred racing as well as breeding in the United States. The loss of breeding records during the American Civil War and the late beginning of the registration of American Thoroughbreds led many in the British racing establishment to doubt that the American-bred horses were purebred.\n",
    "'''\n",
    "\n",
    "result = ppl(question = question, context=context)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "{'score': 0.03040659800171852,\n",
       " 'start': 31,\n",
       " 'end': 100,\n",
       " 'answer': 'to prevent the registration of most American-bred Thoroughbred horses'}"
      ]
     },
     "execution_count": 4,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "result"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Method 2 : Using `AutoModelForQuestionAnswering` and `AutoTokenizer`"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 35,
   "metadata": {},
   "outputs": [],
   "source": [
    "from transformers import AutoModelForQuestionAnswering, AutoTokenizer\n",
    "import torch"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 27,
   "metadata": {},
   "outputs": [],
   "source": [
    "ckpt = \"bert-large-uncased-whole-word-masking-finetuned-squad\"\n",
    "model = AutoModelForQuestionAnswering.from_pretrained(ckpt)\n",
    "tokenizer = AutoTokenizer.from_pretrained(ckpt)\n",
    "\n",
    "question = \"What is Jersey Act ?\"\n",
    "context = '''\n",
    "The Jersey Act was introduced to prevent the registration of most American-bred Thoroughbred horses in the British General Stud Book. It had its roots in the desire of British horse breeders to halt the influx of American-bred racehorses of possibly impure bloodlines during the early 20th century. Many American-bred horses were exported to Europe to race and retire to a breeding career after a number of U.S. states banned gambling, which depressed Thoroughbred racing as well as breeding in the United States. The loss of breeding records during the American Civil War and the late beginning of the registration of American Thoroughbreds led many in the British racing establishment to doubt that the American-bred horses were purebred.\n",
    "'''\n",
    "\n",
    "inputs = tokenizer(question, context, return_tensors='pt')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 37,
   "metadata": {},
   "outputs": [],
   "source": [
    "with torch.no_grad():\n",
    "    output = model(**inputs)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 38,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "QuestionAnsweringModelOutput(loss=None, start_logits=tensor([[-5.9799, -5.2326, -7.3812, -7.0938, -8.5354, -9.6828, -5.9798,  1.8995,\n",
       "         -0.0590, -3.9374, -0.2013,  0.4523,  2.8736,  1.9362, -4.2128, -2.7480,\n",
       "         -6.0425, -4.3723, -3.2908, -6.8249, -5.2264, -3.4335, -4.4484, -4.2624,\n",
       "         -3.3569, -1.4981, -3.2093, -3.4221, -3.7778, -5.9799,  0.8526, -3.5236,\n",
       "         -4.1442, -3.1097, -5.0712, -2.4119, -1.0609, -6.5987, -0.8546, -3.0012,\n",
       "         -4.7014, -1.0428, -1.5233, -5.1667, -3.7215, -6.0956, -3.3341, -7.4709,\n",
       "         -5.5022, -4.6659, -5.8692, -5.9974, -2.5143, -4.0405, -5.4671, -4.9356,\n",
       "         -4.9968, -6.2823, -6.6198, -5.3579, -5.4446, -6.3360, -6.0737, -3.6126,\n",
       "         -4.6887, -8.1716, -6.6218, -5.7185, -7.2662, -5.4052, -7.9011, -5.7640,\n",
       "         -7.0935, -6.0692, -8.7138, -6.2634, -7.6737, -7.5064, -5.3030, -6.9123,\n",
       "         -6.2390, -6.6331, -6.7438, -8.1749, -5.6635, -8.0700, -8.0389, -8.7232,\n",
       "         -7.0600, -4.6931, -5.7083, -7.5999, -6.5596, -4.5272, -5.2904, -6.2583,\n",
       "         -8.6366, -8.4417, -8.8219, -5.6431, -8.0028, -8.0004, -6.9157, -7.5496,\n",
       "         -7.4789, -5.8423, -4.9112, -7.9688, -5.8769, -7.0640, -7.7600, -7.6231,\n",
       "         -6.6751, -7.6596, -7.6487, -8.3420, -7.4217, -6.3540, -7.6716, -8.3178,\n",
       "         -7.5223, -5.2422, -8.1048, -6.3572, -5.8991, -8.0332, -7.2577, -6.6319,\n",
       "         -8.0704, -7.5430, -4.4654, -6.1983, -7.3456, -7.8994, -5.4005, -6.9130,\n",
       "         -6.5947, -4.9338, -8.6510, -7.3953, -6.4204, -7.4020, -4.3367, -7.2049,\n",
       "         -7.6410, -8.6950, -5.9798]]), end_logits=tensor([[-2.0563, -4.3700, -6.3356, -7.4680, -5.5191, -7.5699, -2.0563, -4.4589,\n",
       "         -2.2190, -0.6997, -5.5305, -1.8209, -4.5096, -2.8631, -5.8620, -0.7474,\n",
       "         -5.1972, -3.9878, -4.1467, -6.0003, -3.6780, -2.5292,  1.9761, -3.8984,\n",
       "         -5.5504, -2.8791, -4.1022, -2.9244,  4.4812, -2.0562, -4.3858, -6.4456,\n",
       "         -6.4200, -4.9688, -6.6923, -6.9251, -3.8349, -7.4202, -4.3017, -5.3542,\n",
       "         -1.3172, -6.3408, -4.5845, -7.3681, -3.2369, -6.9047, -5.1281, -6.8679,\n",
       "         -4.5830, -4.1205, -0.4353, -7.0062, -5.3609, -5.6535, -3.5343, -4.0782,\n",
       "          1.5600, -6.1478, -7.5462, -7.1269, -5.4097,  0.0675,  0.2556, -6.7698,\n",
       "         -6.8143, -7.6101, -6.6528, -5.5284, -7.0492, -6.0170, -7.4193, -3.3828,\n",
       "         -7.1803, -5.1811, -7.4383, -5.9125, -7.7599, -7.8256, -6.0786, -3.0228,\n",
       "         -5.3050, -7.7605, -6.5265, -7.6916, -7.4367, -7.6126, -7.5676, -7.5351,\n",
       "         -6.3011, -6.1092, -3.4178, -3.9419, -7.4683, -6.3867, -6.7723, -4.1661,\n",
       "         -8.2239, -7.5994, -8.0972, -5.2862, -8.3141, -8.2333, -7.7119, -3.9006,\n",
       "         -3.1638, -7.4876, -6.9985, -8.1061, -7.1634, -4.7953, -7.5186, -7.8204,\n",
       "         -7.3788, -7.1839, -5.2924, -7.5559, -8.2604, -7.4640, -6.8225, -8.2988,\n",
       "         -8.6287, -5.8702, -8.2078, -7.2136, -6.7952, -4.7434, -7.9310, -7.3872,\n",
       "         -8.2470, -8.4797, -5.8039, -5.9990, -5.8994, -8.3762, -6.3122, -7.8183,\n",
       "         -8.5849, -7.0885, -8.1472, -7.5429, -6.4062, -7.5707, -6.8643, -6.9812,\n",
       "         -2.2833, -3.3852, -2.0565]]), hidden_states=None, attentions=None)"
      ]
     },
     "execution_count": 38,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "output"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 42,
   "metadata": {},
   "outputs": [],
   "source": [
    "start_index = output[\"start_logits\"].argmax()\n",
    "end_index = output[\"end_logits\"].argmax()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 46,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "tensor(12)"
      ]
     },
     "execution_count": 46,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "start_index"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 47,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "tensor(28)"
      ]
     },
     "execution_count": 47,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "end_index"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 53,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "'to prevent the registration of most american - bred thoroughbred horses in the british general stud book'"
      ]
     },
     "execution_count": 53,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "output_ids = inputs[\"input_ids\"][0][start_index:end_index+1]\n",
    "\" \".join(tokenizer.convert_ids_to_tokens(output_ids))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "{'input_ids': tensor([[  101,  2054,  2003,  3933,  2552,  1029, 17371, 10343,  2094,  5620,\n",
       "          2546,  5620,  2546, 21724,  2546,   102,  1996,  3933,  2552,  2001,\n",
       "          3107,  2000,  4652,  1996,  8819,  1997,  2087,  2137,  1011, 13680,\n",
       "         18359,  5194,  1999,  1996,  2329,  2236, 16054,  2338,  1012,  2009,\n",
       "          2018,  2049,  6147,  1999,  1996,  4792,  1997,  2329,  3586, 20823,\n",
       "          2000,  9190,  1996, 18050,  1997,  2137,  1011, 13680, 25068,  2015,\n",
       "          1997,  4298, 17727,  5397,  2668, 12735,  2076,  1996,  2220,  3983,\n",
       "          2301,  1012,  2116,  2137,  1011, 13680,  5194,  2020, 15612,  2000,\n",
       "          2885,  2000,  2679,  1998, 11036,  2000,  1037,  8119,  2476,  2044,\n",
       "          1037,  2193,  1997,  1057,  1012,  1055,  1012,  2163,  7917, 12219,\n",
       "          1010,  2029, 14777, 18359,  3868,  2004,  2092,  2004,  8119,  1999,\n",
       "          1996,  2142,  2163,  1012,  1996,  3279,  1997,  8119,  2636,  2076,\n",
       "          1996,  2137,  2942,  2162,  1998,  1996,  2397,  2927,  1997,  1996,\n",
       "          8819,  1997,  2137, 18359,  2015,  2419,  2116,  1999,  1996,  2329,\n",
       "          3868,  5069,  2000,  4797,  2008,  1996,  2137,  1011, 13680,  5194,\n",
       "          2020,  5760, 13578,  2094,  1012,   102]]), 'token_type_ids': tensor([[0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 1, 1, 1, 1, 1, 1, 1, 1,\n",
       "         1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1,\n",
       "         1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1,\n",
       "         1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1,\n",
       "         1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1,\n",
       "         1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1,\n",
       "         1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1]]), 'attention_mask': tensor([[1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1,\n",
       "         1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1,\n",
       "         1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1,\n",
       "         1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1,\n",
       "         1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1,\n",
       "         1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1,\n",
       "         1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1]])}"
      ]
     },
     "execution_count": 22,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "inputs"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "tensor([  101,  2054,  2003,  3933,  2552,  1029, 17371, 10343,  2094,  5620,\n",
       "         2546,  5620,  2546, 21724,  2546,   102,  1996,  3933,  2552,  2001,\n",
       "         3107,  2000,  4652,  1996,  8819,  1997,  2087,  2137,  1011, 13680,\n",
       "        18359,  5194,  1999,  1996,  2329,  2236, 16054,  2338,  1012,  2009,\n",
       "         2018,  2049,  6147,  1999,  1996,  4792,  1997,  2329,  3586, 20823,\n",
       "         2000,  9190,  1996, 18050,  1997,  2137,  1011, 13680, 25068,  2015,\n",
       "         1997,  4298, 17727,  5397,  2668, 12735,  2076,  1996,  2220,  3983,\n",
       "         2301,  1012,  2116,  2137,  1011, 13680,  5194,  2020, 15612,  2000,\n",
       "         2885,  2000,  2679,  1998, 11036,  2000,  1037,  8119,  2476,  2044,\n",
       "         1037,  2193,  1997,  1057,  1012,  1055,  1012,  2163,  7917, 12219,\n",
       "         1010,  2029, 14777, 18359,  3868,  2004,  2092,  2004,  8119,  1999,\n",
       "         1996,  2142,  2163,  1012,  1996,  3279,  1997,  8119,  2636,  2076,\n",
       "         1996,  2137,  2942,  2162,  1998,  1996,  2397,  2927,  1997,  1996,\n",
       "         8819,  1997,  2137, 18359,  2015,  2419,  2116,  1999,  1996,  2329,\n",
       "         3868,  5069,  2000,  4797,  2008,  1996,  2137,  1011, 13680,  5194,\n",
       "         2020,  5760, 13578,  2094,  1012,   102])"
      ]
     },
     "execution_count": 23,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "inputs[\"input_ids\"][0]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "['[CLS]',\n",
       " 'what',\n",
       " 'is',\n",
       " 'jersey',\n",
       " 'act',\n",
       " '?',\n",
       " 'sd',\n",
       " '##fs',\n",
       " '##d',\n",
       " '##gs',\n",
       " '##f',\n",
       " '##gs',\n",
       " '##f',\n",
       " '##wd',\n",
       " '##f',\n",
       " '[SEP]',\n",
       " 'the',\n",
       " 'jersey',\n",
       " 'act',\n",
       " 'was',\n",
       " 'introduced',\n",
       " 'to',\n",
       " 'prevent',\n",
       " 'the',\n",
       " 'registration',\n",
       " 'of',\n",
       " 'most',\n",
       " 'american',\n",
       " '-',\n",
       " 'bred',\n",
       " 'thoroughbred',\n",
       " 'horses',\n",
       " 'in',\n",
       " 'the',\n",
       " 'british',\n",
       " 'general',\n",
       " 'stud',\n",
       " 'book',\n",
       " '.',\n",
       " 'it',\n",
       " 'had',\n",
       " 'its',\n",
       " 'roots',\n",
       " 'in',\n",
       " 'the',\n",
       " 'desire',\n",
       " 'of',\n",
       " 'british',\n",
       " 'horse',\n",
       " 'breeders',\n",
       " 'to',\n",
       " 'halt',\n",
       " 'the',\n",
       " 'influx',\n",
       " 'of',\n",
       " 'american',\n",
       " '-',\n",
       " 'bred',\n",
       " 'racehorse',\n",
       " '##s',\n",
       " 'of',\n",
       " 'possibly',\n",
       " 'imp',\n",
       " '##ure',\n",
       " 'blood',\n",
       " '##lines',\n",
       " 'during',\n",
       " 'the',\n",
       " 'early',\n",
       " '20th',\n",
       " 'century',\n",
       " '.',\n",
       " 'many',\n",
       " 'american',\n",
       " '-',\n",
       " 'bred',\n",
       " 'horses',\n",
       " 'were',\n",
       " 'exported',\n",
       " 'to',\n",
       " 'europe',\n",
       " 'to',\n",
       " 'race',\n",
       " 'and',\n",
       " 'retire',\n",
       " 'to',\n",
       " 'a',\n",
       " 'breeding',\n",
       " 'career',\n",
       " 'after',\n",
       " 'a',\n",
       " 'number',\n",
       " 'of',\n",
       " 'u',\n",
       " '.',\n",
       " 's',\n",
       " '.',\n",
       " 'states',\n",
       " 'banned',\n",
       " 'gambling',\n",
       " ',',\n",
       " 'which',\n",
       " 'depressed',\n",
       " 'thoroughbred',\n",
       " 'racing',\n",
       " 'as',\n",
       " 'well',\n",
       " 'as',\n",
       " 'breeding',\n",
       " 'in',\n",
       " 'the',\n",
       " 'united',\n",
       " 'states',\n",
       " '.',\n",
       " 'the',\n",
       " 'loss',\n",
       " 'of',\n",
       " 'breeding',\n",
       " 'records',\n",
       " 'during',\n",
       " 'the',\n",
       " 'american',\n",
       " 'civil',\n",
       " 'war',\n",
       " 'and',\n",
       " 'the',\n",
       " 'late',\n",
       " 'beginning',\n",
       " 'of',\n",
       " 'the',\n",
       " 'registration',\n",
       " 'of',\n",
       " 'american',\n",
       " 'thoroughbred',\n",
       " '##s',\n",
       " 'led',\n",
       " 'many',\n",
       " 'in',\n",
       " 'the',\n",
       " 'british',\n",
       " 'racing',\n",
       " 'establishment',\n",
       " 'to',\n",
       " 'doubt',\n",
       " 'that',\n",
       " 'the',\n",
       " 'american',\n",
       " '-',\n",
       " 'bred',\n",
       " 'horses',\n",
       " 'were',\n",
       " 'pure',\n",
       " '##bre',\n",
       " '##d',\n",
       " '.',\n",
       " '[SEP]']"
      ]
     },
     "execution_count": 24,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "tokenizer.convert_ids_to_tokens(inputs[\"input_ids\"][0])"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "pytorch",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.10"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
