{
  "cells": [
    {
      "cell_type": "code",
      "execution_count": 2,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "XUYkVywtX0BG",
        "outputId": "6ae80749-6d49-45b2-c6d8-ffd344fde018"
      },
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Collecting soundfile\n",
            "  Downloading soundfile-0.13.1-py2.py3-none-win_amd64.whl.metadata (16 kB)\n",
            "Requirement already satisfied: cffi>=1.0 in c:\\users\\hp\\anaconda3\\lib\\site-packages (from soundfile) (1.16.0)\n",
            "Requirement already satisfied: numpy in c:\\users\\hp\\anaconda3\\lib\\site-packages (from soundfile) (1.24.4)\n",
            "Requirement already satisfied: pycparser in c:\\users\\hp\\anaconda3\\lib\\site-packages (from cffi>=1.0->soundfile) (2.21)\n",
            "Downloading soundfile-0.13.1-py2.py3-none-win_amd64.whl (1.0 MB)\n",
            "   ---------------------------------------- 0.0/1.0 MB ? eta -:--:--\n",
            "   -- ------------------------------------- 0.1/1.0 MB 2.0 MB/s eta 0:00:01\n",
            "   ----- ---------------------------------- 0.1/1.0 MB 1.6 MB/s eta 0:00:01\n",
            "   ---------- ----------------------------- 0.3/1.0 MB 2.1 MB/s eta 0:00:01\n",
            "   --------------- ------------------------ 0.4/1.0 MB 2.3 MB/s eta 0:00:01\n",
            "   -------------------- ------------------- 0.5/1.0 MB 2.3 MB/s eta 0:00:01\n",
            "   ------------------------- -------------- 0.6/1.0 MB 2.4 MB/s eta 0:00:01\n",
            "   ------------------------------ --------- 0.8/1.0 MB 2.4 MB/s eta 0:00:01\n",
            "   --------------------------------- ------ 0.8/1.0 MB 2.3 MB/s eta 0:00:01\n",
            "   ------------------------------------- -- 1.0/1.0 MB 2.3 MB/s eta 0:00:01\n",
            "   ---------------------------------------  1.0/1.0 MB 2.4 MB/s eta 0:00:01\n",
            "   ---------------------------------------  1.0/1.0 MB 2.4 MB/s eta 0:00:01\n",
            "   ---------------------------------------- 1.0/1.0 MB 1.9 MB/s eta 0:00:00\n",
            "Installing collected packages: soundfile\n",
            "Successfully installed soundfile-0.13.1\n"
          ]
        }
      ],
      "source": [
        "! pip install soundfile"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 4,
      "metadata": {},
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "2.8.0+cpu\n",
            "CUDA available: False\n"
          ]
        }
      ],
      "source": [
        "import torch\n",
        "print(torch.__version__)\n",
        "print(\"CUDA available:\", torch.cuda.is_available())"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 6,
      "metadata": {},
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Collecting transformersNote: you may need to restart the kernel to use updated packages.\n",
            "\n",
            "  Downloading transformers-4.55.0-py3-none-any.whl.metadata (39 kB)\n",
            "Requirement already satisfied: filelock in c:\\users\\hp\\anaconda3\\lib\\site-packages (from transformers) (3.13.1)\n",
            "Collecting huggingface-hub<1.0,>=0.34.0 (from transformers)\n",
            "  Downloading huggingface_hub-0.34.4-py3-none-any.whl.metadata (14 kB)\n",
            "Requirement already satisfied: numpy>=1.17 in c:\\users\\hp\\anaconda3\\lib\\site-packages (from transformers) (1.24.4)\n",
            "Requirement already satisfied: packaging>=20.0 in c:\\users\\hp\\anaconda3\\lib\\site-packages (from transformers) (23.1)\n",
            "Requirement already satisfied: pyyaml>=5.1 in c:\\users\\hp\\anaconda3\\lib\\site-packages (from transformers) (6.0.1)\n",
            "Requirement already satisfied: regex!=2019.12.17 in c:\\users\\hp\\anaconda3\\lib\\site-packages (from transformers) (2023.10.3)\n",
            "Requirement already satisfied: requests in c:\\users\\hp\\anaconda3\\lib\\site-packages (from transformers) (2.32.3)\n",
            "Collecting tokenizers<0.22,>=0.21 (from transformers)\n",
            "  Downloading tokenizers-0.21.4-cp39-abi3-win_amd64.whl.metadata (6.9 kB)\n",
            "Collecting safetensors>=0.4.3 (from transformers)\n",
            "  Downloading safetensors-0.6.2-cp38-abi3-win_amd64.whl.metadata (4.1 kB)\n",
            "Requirement already satisfied: tqdm>=4.27 in c:\\users\\hp\\anaconda3\\lib\\site-packages (from transformers) (4.65.0)\n",
            "Requirement already satisfied: fsspec>=2023.5.0 in c:\\users\\hp\\anaconda3\\lib\\site-packages (from huggingface-hub<1.0,>=0.34.0->transformers) (2023.10.0)\n",
            "Requirement already satisfied: typing-extensions>=3.7.4.3 in c:\\users\\hp\\anaconda3\\lib\\site-packages (from huggingface-hub<1.0,>=0.34.0->transformers) (4.12.2)\n",
            "Requirement already satisfied: colorama in c:\\users\\hp\\anaconda3\\lib\\site-packages (from tqdm>=4.27->transformers) (0.4.6)\n",
            "Requirement already satisfied: charset-normalizer<4,>=2 in c:\\users\\hp\\anaconda3\\lib\\site-packages (from requests->transformers) (2.0.4)\n",
            "Requirement already satisfied: idna<4,>=2.5 in c:\\users\\hp\\anaconda3\\lib\\site-packages (from requests->transformers) (3.4)\n",
            "Requirement already satisfied: urllib3<3,>=1.21.1 in c:\\users\\hp\\anaconda3\\lib\\site-packages (from requests->transformers) (2.0.7)\n",
            "Requirement already satisfied: certifi>=2017.4.17 in c:\\users\\hp\\anaconda3\\lib\\site-packages (from requests->transformers) (2025.1.31)\n",
            "Downloading transformers-4.55.0-py3-none-any.whl (11.3 MB)\n",
            "   ---------------------------------------- 0.0/11.3 MB ? eta -:--:--\n",
            "   ---------------------------------------- 0.0/11.3 MB 1.4 MB/s eta 0:00:09\n",
            "   ---------------------------------------- 0.1/11.3 MB 1.2 MB/s eta 0:00:10\n",
            "   - -------------------------------------- 0.3/11.3 MB 2.2 MB/s eta 0:00:05\n",
            "   -- ------------------------------------- 0.6/11.3 MB 3.2 MB/s eta 0:00:04\n",
            "   ---- ----------------------------------- 1.2/11.3 MB 4.8 MB/s eta 0:00:03\n",
            "   ----- ---------------------------------- 1.5/11.3 MB 5.1 MB/s eta 0:00:02\n",
            "   ------ --------------------------------- 1.8/11.3 MB 5.3 MB/s eta 0:00:02\n",
            "   ------ --------------------------------- 1.8/11.3 MB 5.3 MB/s eta 0:00:02\n",
            "   ------ --------------------------------- 1.8/11.3 MB 4.2 MB/s eta 0:00:03\n",
            "   -------- ------------------------------- 2.4/11.3 MB 5.0 MB/s eta 0:00:02\n",
            "   ---------- ----------------------------- 2.9/11.3 MB 5.2 MB/s eta 0:00:02\n",
            "   ----------- ---------------------------- 3.3/11.3 MB 5.5 MB/s eta 0:00:02\n",
            "   ------------ --------------------------- 3.6/11.3 MB 5.9 MB/s eta 0:00:02\n",
            "   ------------- -------------------------- 3.7/11.3 MB 5.4 MB/s eta 0:00:02\n",
            "   ------------- -------------------------- 3.9/11.3 MB 5.3 MB/s eta 0:00:02\n",
            "   --------------- ------------------------ 4.3/11.3 MB 5.4 MB/s eta 0:00:02\n",
            "   ---------------- ----------------------- 4.6/11.3 MB 5.5 MB/s eta 0:00:02\n",
            "   ------------------ --------------------- 5.2/11.3 MB 5.8 MB/s eta 0:00:02\n",
            "   ------------------- -------------------- 5.4/11.3 MB 5.7 MB/s eta 0:00:02\n",
            "   -------------------- ------------------- 5.9/11.3 MB 5.9 MB/s eta 0:00:01\n",
            "   ---------------------- ----------------- 6.2/11.3 MB 6.0 MB/s eta 0:00:01\n",
            "   ----------------------- ---------------- 6.6/11.3 MB 5.9 MB/s eta 0:00:01\n",
            "   ------------------------ --------------- 6.8/11.3 MB 5.8 MB/s eta 0:00:01\n",
            "   -------------------------- ------------- 7.4/11.3 MB 6.1 MB/s eta 0:00:01\n",
            "   --------------------------- ------------ 7.7/11.3 MB 6.0 MB/s eta 0:00:01\n",
            "   ---------------------------- ----------- 8.0/11.3 MB 6.1 MB/s eta 0:00:01\n",
            "   ----------------------------- ---------- 8.3/11.3 MB 6.0 MB/s eta 0:00:01\n",
            "   ------------------------------ --------- 8.5/11.3 MB 5.9 MB/s eta 0:00:01\n",
            "   ------------------------------ --------- 8.7/11.3 MB 5.9 MB/s eta 0:00:01\n",
            "   -------------------------------- ------- 9.1/11.3 MB 5.9 MB/s eta 0:00:01\n",
            "   -------------------------------- ------- 9.2/11.3 MB 5.9 MB/s eta 0:00:01\n",
            "   --------------------------------- ------ 9.4/11.3 MB 5.8 MB/s eta 0:00:01\n",
            "   ---------------------------------- ----- 9.7/11.3 MB 5.8 MB/s eta 0:00:01\n",
            "   ----------------------------------- ---- 9.9/11.3 MB 5.7 MB/s eta 0:00:01\n",
            "   ----------------------------------- ---- 10.0/11.3 MB 5.6 MB/s eta 0:00:01\n",
            "   ----------------------------------- ---- 10.0/11.3 MB 5.6 MB/s eta 0:00:01\n",
            "   ------------------------------------ --- 10.3/11.3 MB 5.6 MB/s eta 0:00:01\n",
            "   ------------------------------------- -- 10.4/11.3 MB 5.6 MB/s eta 0:00:01\n",
            "   -------------------------------------- - 10.7/11.3 MB 5.7 MB/s eta 0:00:01\n",
            "   -------------------------------------- - 10.9/11.3 MB 5.6 MB/s eta 0:00:01\n",
            "   ---------------------------------------  11.2/11.3 MB 5.5 MB/s eta 0:00:01\n",
            "   ---------------------------------------  11.3/11.3 MB 5.5 MB/s eta 0:00:01\n",
            "   ---------------------------------------  11.3/11.3 MB 5.5 MB/s eta 0:00:01\n",
            "   ---------------------------------------  11.3/11.3 MB 5.5 MB/s eta 0:00:01\n",
            "   ---------------------------------------- 11.3/11.3 MB 5.0 MB/s eta 0:00:00\n",
            "Downloading huggingface_hub-0.34.4-py3-none-any.whl (561 kB)\n",
            "   ---------------------------------------- 0.0/561.5 kB ? eta -:--:--\n",
            "   -------------------- ------------------- 286.7/561.5 kB 8.9 MB/s eta 0:00:01\n",
            "   --------------------- ------------------ 307.2/561.5 kB 6.5 MB/s eta 0:00:01\n",
            "   ---------------------------------- ----- 481.3/561.5 kB 4.3 MB/s eta 0:00:01\n",
            "   ---------------------------------------  553.0/561.5 kB 3.9 MB/s eta 0:00:01\n",
            "   ---------------------------------------- 561.5/561.5 kB 2.7 MB/s eta 0:00:00\n",
            "Downloading safetensors-0.6.2-cp38-abi3-win_amd64.whl (320 kB)\n",
            "   ---------------------------------------- 0.0/320.2 kB ? eta -:--:--\n",
            "   ---------------------------------------  317.4/320.2 kB 9.6 MB/s eta 0:00:01\n",
            "   ---------------------------------------- 320.2/320.2 kB 3.9 MB/s eta 0:00:00\n",
            "Downloading tokenizers-0.21.4-cp39-abi3-win_amd64.whl (2.5 MB)\n",
            "   ---------------------------------------- 0.0/2.5 MB ? eta -:--:--\n",
            "   ----- ---------------------------------- 0.4/2.5 MB 11.2 MB/s eta 0:00:01\n",
            "   ---------- ----------------------------- 0.6/2.5 MB 8.1 MB/s eta 0:00:01\n",
            "   ------------- -------------------------- 0.8/2.5 MB 6.0 MB/s eta 0:00:01\n",
            "   ------------------ --------------------- 1.1/2.5 MB 6.0 MB/s eta 0:00:01\n",
            "   ---------------------- ----------------- 1.4/2.5 MB 5.8 MB/s eta 0:00:01\n",
            "   --------------------------- ------------ 1.7/2.5 MB 6.1 MB/s eta 0:00:01\n",
            "   ------------------------------- -------- 2.0/2.5 MB 5.9 MB/s eta 0:00:01\n",
            "   ------------------------------- -------- 2.0/2.5 MB 5.3 MB/s eta 0:00:01\n",
            "   ---------------------------------------  2.5/2.5 MB 5.6 MB/s eta 0:00:01\n",
            "   ---------------------------------------  2.5/2.5 MB 5.5 MB/s eta 0:00:01\n",
            "   ---------------------------------------  2.5/2.5 MB 5.5 MB/s eta 0:00:01\n",
            "   ---------------------------------------  2.5/2.5 MB 5.5 MB/s eta 0:00:01\n",
            "   ---------------------------------------  2.5/2.5 MB 5.5 MB/s eta 0:00:01\n",
            "   ---------------------------------------  2.5/2.5 MB 5.5 MB/s eta 0:00:01\n",
            "   ---------------------------------------  2.5/2.5 MB 5.5 MB/s eta 0:00:01\n",
            "   ---------------------------------------  2.5/2.5 MB 5.5 MB/s eta 0:00:01\n",
            "   ---------------------------------------  2.5/2.5 MB 5.5 MB/s eta 0:00:01\n",
            "   ---------------------------------------  2.5/2.5 MB 5.5 MB/s eta 0:00:01\n",
            "   ---------------------------------------  2.5/2.5 MB 5.5 MB/s eta 0:00:01\n",
            "   ---------------------------------------  2.5/2.5 MB 5.5 MB/s eta 0:00:01\n",
            "   ---------------------------------------  2.5/2.5 MB 5.5 MB/s eta 0:00:01\n",
            "   ---------------------------------------  2.5/2.5 MB 5.5 MB/s eta 0:00:01\n",
            "   ---------------------------------------  2.5/2.5 MB 5.5 MB/s eta 0:00:01\n",
            "   ---------------------------------------  2.5/2.5 MB 5.5 MB/s eta 0:00:01\n",
            "   ---------------------------------------  2.5/2.5 MB 5.5 MB/s eta 0:00:01\n",
            "   ---------------------------------------  2.5/2.5 MB 5.5 MB/s eta 0:00:01\n",
            "   ---------------------------------------  2.5/2.5 MB 5.5 MB/s eta 0:00:01\n",
            "   ---------------------------------------  2.5/2.5 MB 5.5 MB/s eta 0:00:01\n",
            "   ---------------------------------------  2.5/2.5 MB 5.5 MB/s eta 0:00:01\n",
            "   ---------------------------------------  2.5/2.5 MB 5.5 MB/s eta 0:00:01\n",
            "   ---------------------------------------  2.5/2.5 MB 5.5 MB/s eta 0:00:01\n",
            "   ---------------------------------------  2.5/2.5 MB 5.5 MB/s eta 0:00:01\n",
            "   ---------------------------------------  2.5/2.5 MB 5.5 MB/s eta 0:00:01\n",
            "   ---------------------------------------  2.5/2.5 MB 5.5 MB/s eta 0:00:01\n",
            "   ---------------------------------------- 2.5/2.5 MB 1.5 MB/s eta 0:00:00\n",
            "Installing collected packages: safetensors, huggingface-hub, tokenizers, transformers\n",
            "Successfully installed huggingface-hub-0.34.4 safetensors-0.6.2 tokenizers-0.21.4 transformers-4.55.0\n"
          ]
        }
      ],
      "source": [
        "pip install transformers"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 8,
      "metadata": {},
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Collecting librosa\n",
            "  Downloading librosa-0.11.0-py3-none-any.whl.metadata (8.7 kB)\n",
            "Collecting audioread>=2.1.9 (from librosa)\n",
            "  Downloading audioread-3.0.1-py3-none-any.whl.metadata (8.4 kB)\n",
            "Requirement already satisfied: numba>=0.51.0 in c:\\users\\hp\\anaconda3\\lib\\site-packages (from librosa) (0.59.0)\n",
            "Requirement already satisfied: numpy>=1.22.3 in c:\\users\\hp\\anaconda3\\lib\\site-packages (from librosa) (1.24.4)\n",
            "Requirement already satisfied: scipy>=1.6.0 in c:\\users\\hp\\anaconda3\\lib\\site-packages (from librosa) (1.11.4)\n",
            "Requirement already satisfied: scikit-learn>=1.1.0 in c:\\users\\hp\\anaconda3\\lib\\site-packages (from librosa) (1.2.2)\n",
            "Requirement already satisfied: joblib>=1.0 in c:\\users\\hp\\anaconda3\\lib\\site-packages (from librosa) (1.2.0)\n",
            "Requirement already satisfied: decorator>=4.3.0 in c:\\users\\hp\\anaconda3\\lib\\site-packages (from librosa) (5.1.1)\n",
            "Requirement already satisfied: soundfile>=0.12.1 in c:\\users\\hp\\anaconda3\\lib\\site-packages (from librosa) (0.13.1)\n",
            "Collecting pooch>=1.1 (from librosa)\n",
            "  Downloading pooch-1.8.2-py3-none-any.whl.metadata (10 kB)\n",
            "Collecting soxr>=0.3.2 (from librosa)\n",
            "  Downloading soxr-0.5.0.post1-cp311-cp311-win_amd64.whl.metadata (5.6 kB)\n",
            "Requirement already satisfied: typing_extensions>=4.1.1 in c:\\users\\hp\\anaconda3\\lib\\site-packages (from librosa) (4.12.2)\n",
            "Requirement already satisfied: lazy_loader>=0.1 in c:\\users\\hp\\anaconda3\\lib\\site-packages (from librosa) (0.3)\n",
            "Requirement already satisfied: msgpack>=1.0 in c:\\users\\hp\\anaconda3\\lib\\site-packages (from librosa) (1.0.3)\n",
            "Requirement already satisfied: llvmlite<0.43,>=0.42.0dev0 in c:\\users\\hp\\anaconda3\\lib\\site-packages (from numba>=0.51.0->librosa) (0.42.0)\n",
            "Requirement already satisfied: platformdirs>=2.5.0 in c:\\users\\hp\\anaconda3\\lib\\site-packages (from pooch>=1.1->librosa) (3.10.0)\n",
            "Requirement already satisfied: packaging>=20.0 in c:\\users\\hp\\anaconda3\\lib\\site-packages (from pooch>=1.1->librosa) (23.1)\n",
            "Requirement already satisfied: requests>=2.19.0 in c:\\users\\hp\\anaconda3\\lib\\site-packages (from pooch>=1.1->librosa) (2.32.3)\n",
            "Requirement already satisfied: threadpoolctl>=2.0.0 in c:\\users\\hp\\anaconda3\\lib\\site-packages (from scikit-learn>=1.1.0->librosa) (2.2.0)\n",
            "Requirement already satisfied: cffi>=1.0 in c:\\users\\hp\\anaconda3\\lib\\site-packages (from soundfile>=0.12.1->librosa) (1.16.0)\n",
            "Requirement already satisfied: pycparser in c:\\users\\hp\\anaconda3\\lib\\site-packages (from cffi>=1.0->soundfile>=0.12.1->librosa) (2.21)\n",
            "Requirement already satisfied: charset-normalizer<4,>=2 in c:\\users\\hp\\anaconda3\\lib\\site-packages (from requests>=2.19.0->pooch>=1.1->librosa) (2.0.4)\n",
            "Requirement already satisfied: idna<4,>=2.5 in c:\\users\\hp\\anaconda3\\lib\\site-packages (from requests>=2.19.0->pooch>=1.1->librosa) (3.4)\n",
            "Requirement already satisfied: urllib3<3,>=1.21.1 in c:\\users\\hp\\anaconda3\\lib\\site-packages (from requests>=2.19.0->pooch>=1.1->librosa) (2.0.7)\n",
            "Requirement already satisfied: certifi>=2017.4.17 in c:\\users\\hp\\anaconda3\\lib\\site-packages (from requests>=2.19.0->pooch>=1.1->librosa) (2025.1.31)\n",
            "Downloading librosa-0.11.0-py3-none-any.whl (260 kB)\n",
            "   ---------------------------------------- 0.0/260.7 kB ? eta -:--:--\n",
            "   ---------------------------------------  256.0/260.7 kB 7.9 MB/s eta 0:00:01\n",
            "   ---------------------------------------  256.0/260.7 kB 7.9 MB/s eta 0:00:01\n",
            "   ---------------------------------------- 260.7/260.7 kB 2.3 MB/s eta 0:00:00\n",
            "Downloading audioread-3.0.1-py3-none-any.whl (23 kB)\n",
            "Downloading pooch-1.8.2-py3-none-any.whl (64 kB)\n",
            "   ---------------------------------------- 0.0/64.6 kB ? eta -:--:--\n",
            "   -------------------------------------- - 61.4/64.6 kB ? eta -:--:--\n",
            "   ---------------------------------------- 64.6/64.6 kB 1.2 MB/s eta 0:00:00\n",
            "Downloading soxr-0.5.0.post1-cp311-cp311-win_amd64.whl (166 kB)\n",
            "   ---------------------------------------- 0.0/166.7 kB ? eta -:--:--\n",
            "   ---------------------------------------  163.8/166.7 kB 3.3 MB/s eta 0:00:01\n",
            "   ---------------------------------------- 166.7/166.7 kB 1.7 MB/s eta 0:00:00\n",
            "Installing collected packages: soxr, audioread, pooch, librosa\n",
            "Successfully installed audioread-3.0.1 librosa-0.11.0 pooch-1.8.2 soxr-0.5.0.post1\n",
            "Note: you may need to restart the kernel to use updated packages.\n"
          ]
        }
      ],
      "source": [
        "pip install librosa"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 9,
      "metadata": {
        "id": "eqDillhaA_d4"
      },
      "outputs": [],
      "source": [
        "import pandas as pd\n",
        "import torch\n",
        "import torchaudio\n",
        "import numpy as np\n",
        "from transformers import AutoFeatureExtractor, AutoModelForAudioClassification\n",
        "import soundfile as sf\n",
        "import librosa\n",
        "import warnings\n",
        "warnings.filterwarnings('ignore')\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 10,
      "metadata": {
        "id": "25xABVaNBKM1"
      },
      "outputs": [],
      "source": [
        "# Load pre-trained models directly\n",
        "device = torch.device(\"cuda\" if torch.cuda.is_available() else \"cpu\")"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 11,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "kkrbofAqBYbN",
        "outputId": "0ba506ba-874d-4d31-caff-2cb011e54bff"
      },
      "outputs": [
        {
          "data": {
            "application/vnd.jupyter.widget-view+json": {
              "model_id": "d76e060462384a8ab004c5e049f1af1f",
              "version_major": 2,
              "version_minor": 0
            },
            "text/plain": [
              "config.json: 0.00B [00:00, ?B/s]"
            ]
          },
          "metadata": {},
          "output_type": "display_data"
        },
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "Xet Storage is enabled for this repo, but the 'hf_xet' package is not installed. Falling back to regular HTTP download. For better performance, install the package with: `pip install huggingface_hub[hf_xet]` or `pip install hf_xet`\n"
          ]
        },
        {
          "data": {
            "application/vnd.jupyter.widget-view+json": {
              "model_id": "38fcd3139b684bde80361bdfa396cff4",
              "version_major": 2,
              "version_minor": 0
            },
            "text/plain": [
              "model.safetensors:   0%|          | 0.00/346M [00:00<?, ?B/s]"
            ]
          },
          "metadata": {},
          "output_type": "display_data"
        },
        {
          "data": {
            "application/vnd.jupyter.widget-view+json": {
              "model_id": "7b3855828e404b5595f8ac31a2ad54fa",
              "version_major": 2,
              "version_minor": 0
            },
            "text/plain": [
              "preprocessor_config.json:   0%|          | 0.00/297 [00:00<?, ?B/s]"
            ]
          },
          "metadata": {},
          "output_type": "display_data"
        },
        {
          "data": {
            "text/plain": [
              "ASTForAudioClassification(\n",
              "  (audio_spectrogram_transformer): ASTModel(\n",
              "    (embeddings): ASTEmbeddings(\n",
              "      (patch_embeddings): ASTPatchEmbeddings(\n",
              "        (projection): Conv2d(1, 768, kernel_size=(16, 16), stride=(10, 10))\n",
              "      )\n",
              "      (dropout): Dropout(p=0.0, inplace=False)\n",
              "    )\n",
              "    (encoder): ASTEncoder(\n",
              "      (layer): ModuleList(\n",
              "        (0-11): 12 x ASTLayer(\n",
              "          (attention): ASTAttention(\n",
              "            (attention): ASTSelfAttention(\n",
              "              (query): Linear(in_features=768, out_features=768, bias=True)\n",
              "              (key): Linear(in_features=768, out_features=768, bias=True)\n",
              "              (value): Linear(in_features=768, out_features=768, bias=True)\n",
              "            )\n",
              "            (output): ASTSelfOutput(\n",
              "              (dense): Linear(in_features=768, out_features=768, bias=True)\n",
              "              (dropout): Dropout(p=0.0, inplace=False)\n",
              "            )\n",
              "          )\n",
              "          (intermediate): ASTIntermediate(\n",
              "            (dense): Linear(in_features=768, out_features=3072, bias=True)\n",
              "            (intermediate_act_fn): GELUActivation()\n",
              "          )\n",
              "          (output): ASTOutput(\n",
              "            (dense): Linear(in_features=3072, out_features=768, bias=True)\n",
              "            (dropout): Dropout(p=0.0, inplace=False)\n",
              "          )\n",
              "          (layernorm_before): LayerNorm((768,), eps=1e-12, elementwise_affine=True)\n",
              "          (layernorm_after): LayerNorm((768,), eps=1e-12, elementwise_affine=True)\n",
              "        )\n",
              "      )\n",
              "    )\n",
              "    (layernorm): LayerNorm((768,), eps=1e-12, elementwise_affine=True)\n",
              "  )\n",
              "  (classifier): ASTMLPHead(\n",
              "    (layernorm): LayerNorm((768,), eps=1e-12, elementwise_affine=True)\n",
              "    (dense): Linear(in_features=768, out_features=527, bias=True)\n",
              "  )\n",
              ")"
            ]
          },
          "execution_count": 11,
          "metadata": {},
          "output_type": "execute_result"
        }
      ],
      "source": [
        "# Audio Spectrogram Transformer\n",
        "ast_model = AutoModelForAudioClassification.from_pretrained(\"MIT/ast-finetuned-audioset-10-10-0.4593\")\n",
        "ast_extractor = AutoFeatureExtractor.from_pretrained(\"MIT/ast-finetuned-audioset-10-10-0.4593\")\n",
        "ast_model.to(device).eval()"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 4,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "0mohu-ofBfGz",
        "outputId": "fafc81bc-4a54-43b9-cb47-7d86cc97d0eb"
      },
      "outputs": [
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "Some weights of Wav2Vec2ForSequenceClassification were not initialized from the model checkpoint at facebook/wav2vec2-base-960h and are newly initialized: ['classifier.bias', 'classifier.weight', 'projector.bias', 'projector.weight', 'wav2vec2.masked_spec_embed']\n",
            "You should probably TRAIN this model on a down-stream task to be able to use it for predictions and inference.\n"
          ]
        },
        {
          "data": {
            "text/plain": [
              "Wav2Vec2ForSequenceClassification(\n",
              "  (wav2vec2): Wav2Vec2Model(\n",
              "    (feature_extractor): Wav2Vec2FeatureEncoder(\n",
              "      (conv_layers): ModuleList(\n",
              "        (0): Wav2Vec2GroupNormConvLayer(\n",
              "          (conv): Conv1d(1, 512, kernel_size=(10,), stride=(5,), bias=False)\n",
              "          (activation): GELUActivation()\n",
              "          (layer_norm): GroupNorm(512, 512, eps=1e-05, affine=True)\n",
              "        )\n",
              "        (1-4): 4 x Wav2Vec2NoLayerNormConvLayer(\n",
              "          (conv): Conv1d(512, 512, kernel_size=(3,), stride=(2,), bias=False)\n",
              "          (activation): GELUActivation()\n",
              "        )\n",
              "        (5-6): 2 x Wav2Vec2NoLayerNormConvLayer(\n",
              "          (conv): Conv1d(512, 512, kernel_size=(2,), stride=(2,), bias=False)\n",
              "          (activation): GELUActivation()\n",
              "        )\n",
              "      )\n",
              "    )\n",
              "    (feature_projection): Wav2Vec2FeatureProjection(\n",
              "      (layer_norm): LayerNorm((512,), eps=1e-05, elementwise_affine=True)\n",
              "      (projection): Linear(in_features=512, out_features=768, bias=True)\n",
              "      (dropout): Dropout(p=0.1, inplace=False)\n",
              "    )\n",
              "    (encoder): Wav2Vec2Encoder(\n",
              "      (pos_conv_embed): Wav2Vec2PositionalConvEmbedding(\n",
              "        (conv): ParametrizedConv1d(\n",
              "          768, 768, kernel_size=(128,), stride=(1,), padding=(64,), groups=16\n",
              "          (parametrizations): ModuleDict(\n",
              "            (weight): ParametrizationList(\n",
              "              (0): _WeightNorm()\n",
              "            )\n",
              "          )\n",
              "        )\n",
              "        (padding): Wav2Vec2SamePadLayer()\n",
              "        (activation): GELUActivation()\n",
              "      )\n",
              "      (layer_norm): LayerNorm((768,), eps=1e-05, elementwise_affine=True)\n",
              "      (dropout): Dropout(p=0.1, inplace=False)\n",
              "      (layers): ModuleList(\n",
              "        (0-11): 12 x Wav2Vec2EncoderLayer(\n",
              "          (attention): Wav2Vec2Attention(\n",
              "            (k_proj): Linear(in_features=768, out_features=768, bias=True)\n",
              "            (v_proj): Linear(in_features=768, out_features=768, bias=True)\n",
              "            (q_proj): Linear(in_features=768, out_features=768, bias=True)\n",
              "            (out_proj): Linear(in_features=768, out_features=768, bias=True)\n",
              "          )\n",
              "          (dropout): Dropout(p=0.1, inplace=False)\n",
              "          (layer_norm): LayerNorm((768,), eps=1e-05, elementwise_affine=True)\n",
              "          (feed_forward): Wav2Vec2FeedForward(\n",
              "            (intermediate_dropout): Dropout(p=0.1, inplace=False)\n",
              "            (intermediate_dense): Linear(in_features=768, out_features=3072, bias=True)\n",
              "            (intermediate_act_fn): GELUActivation()\n",
              "            (output_dense): Linear(in_features=3072, out_features=768, bias=True)\n",
              "            (output_dropout): Dropout(p=0.1, inplace=False)\n",
              "          )\n",
              "          (final_layer_norm): LayerNorm((768,), eps=1e-05, elementwise_affine=True)\n",
              "        )\n",
              "      )\n",
              "    )\n",
              "  )\n",
              "  (projector): Linear(in_features=768, out_features=256, bias=True)\n",
              "  (classifier): Linear(in_features=256, out_features=2, bias=True)\n",
              ")"
            ]
          },
          "execution_count": 4,
          "metadata": {},
          "output_type": "execute_result"
        }
      ],
      "source": [
        "# Wav2Vec2\n",
        "wav2vec_model = AutoModelForAudioClassification.from_pretrained(\"facebook/wav2vec2-base-960h\")\n",
        "wav2vec_extractor = AutoFeatureExtractor.from_pretrained(\"facebook/wav2vec2-base-960h\")\n",
        "wav2vec_model.to(device).eval()"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "KEXiRuNwBmzw",
        "outputId": "f9b5e0b2-3ee8-4bf0-8d83-917e6980c81a"
      },
      "outputs": [
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "Some weights of HubertForSequenceClassification were not initialized from the model checkpoint at facebook/hubert-base-ls960 and are newly initialized: ['classifier.bias', 'classifier.weight', 'projector.bias', 'projector.weight']\n",
            "You should probably TRAIN this model on a down-stream task to be able to use it for predictions and inference.\n"
          ]
        },
        {
          "data": {
            "text/plain": [
              "HubertForSequenceClassification(\n",
              "  (hubert): HubertModel(\n",
              "    (feature_extractor): HubertFeatureEncoder(\n",
              "      (conv_layers): ModuleList(\n",
              "        (0): HubertGroupNormConvLayer(\n",
              "          (conv): Conv1d(1, 512, kernel_size=(10,), stride=(5,), bias=False)\n",
              "          (activation): GELUActivation()\n",
              "          (layer_norm): GroupNorm(512, 512, eps=1e-05, affine=True)\n",
              "        )\n",
              "        (1-4): 4 x HubertNoLayerNormConvLayer(\n",
              "          (conv): Conv1d(512, 512, kernel_size=(3,), stride=(2,), bias=False)\n",
              "          (activation): GELUActivation()\n",
              "        )\n",
              "        (5-6): 2 x HubertNoLayerNormConvLayer(\n",
              "          (conv): Conv1d(512, 512, kernel_size=(2,), stride=(2,), bias=False)\n",
              "          (activation): GELUActivation()\n",
              "        )\n",
              "      )\n",
              "    )\n",
              "    (feature_projection): HubertFeatureProjection(\n",
              "      (layer_norm): LayerNorm((512,), eps=1e-05, elementwise_affine=True)\n",
              "      (projection): Linear(in_features=512, out_features=768, bias=True)\n",
              "      (dropout): Dropout(p=0.1, inplace=False)\n",
              "    )\n",
              "    (encoder): HubertEncoder(\n",
              "      (pos_conv_embed): HubertPositionalConvEmbedding(\n",
              "        (conv): ParametrizedConv1d(\n",
              "          768, 768, kernel_size=(128,), stride=(1,), padding=(64,), groups=16\n",
              "          (parametrizations): ModuleDict(\n",
              "            (weight): ParametrizationList(\n",
              "              (0): _WeightNorm()\n",
              "            )\n",
              "          )\n",
              "        )\n",
              "        (padding): HubertSamePadLayer()\n",
              "        (activation): GELUActivation()\n",
              "      )\n",
              "      (layer_norm): LayerNorm((768,), eps=1e-05, elementwise_affine=True)\n",
              "      (dropout): Dropout(p=0.1, inplace=False)\n",
              "      (layers): ModuleList(\n",
              "        (0-11): 12 x HubertEncoderLayer(\n",
              "          (attention): HubertAttention(\n",
              "            (k_proj): Linear(in_features=768, out_features=768, bias=True)\n",
              "            (v_proj): Linear(in_features=768, out_features=768, bias=True)\n",
              "            (q_proj): Linear(in_features=768, out_features=768, bias=True)\n",
              "            (out_proj): Linear(in_features=768, out_features=768, bias=True)\n",
              "          )\n",
              "          (dropout): Dropout(p=0.1, inplace=False)\n",
              "          (layer_norm): LayerNorm((768,), eps=1e-05, elementwise_affine=True)\n",
              "          (feed_forward): HubertFeedForward(\n",
              "            (intermediate_dropout): Dropout(p=0.1, inplace=False)\n",
              "            (intermediate_dense): Linear(in_features=768, out_features=3072, bias=True)\n",
              "            (intermediate_act_fn): GELUActivation()\n",
              "            (output_dense): Linear(in_features=3072, out_features=768, bias=True)\n",
              "            (output_dropout): Dropout(p=0.1, inplace=False)\n",
              "          )\n",
              "          (final_layer_norm): LayerNorm((768,), eps=1e-05, elementwise_affine=True)\n",
              "        )\n",
              "      )\n",
              "    )\n",
              "  )\n",
              "  (projector): Linear(in_features=768, out_features=256, bias=True)\n",
              "  (classifier): Linear(in_features=256, out_features=2, bias=True)\n",
              ")"
            ]
          },
          "execution_count": 5,
          "metadata": {},
          "output_type": "execute_result"
        }
      ],
      "source": [
        "# HuBERT\n",
        "hubert_model = AutoModelForAudioClassification.from_pretrained(\"facebook/hubert-base-ls960\")\n",
        "hubert_extractor = AutoFeatureExtractor.from_pretrained(\"facebook/hubert-base-ls960\")\n",
        "hubert_model.to(device).eval()"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "LLzQYfI6tUXy"
      },
      "outputs": [],
      "source": [
        "# Load AST class labels from AudioSet\n",
        "url = \"https://raw.githubusercontent.com/qiuqiangkong/audioset_tagging_cnn/master/metadata/class_labels_indices.csv\"\n",
        "labels_df = pd.read_csv(url)\n",
        "class_labels_ast = labels_df['display_name'].tolist()\n",
        "\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 7,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "cFCJNUS7tWoO",
        "outputId": "170152f8-6582-41f6-fe81-472085908dfe"
      },
      "outputs": [
        {
          "data": {
            "text/plain": [
              "['Speech',\n",
              " 'Male speech, man speaking',\n",
              " 'Female speech, woman speaking',\n",
              " 'Child speech, kid speaking',\n",
              " 'Conversation',\n",
              " 'Narration, monologue',\n",
              " 'Babbling',\n",
              " 'Speech synthesizer',\n",
              " 'Shout',\n",
              " 'Bellow',\n",
              " 'Whoop',\n",
              " 'Yell',\n",
              " 'Battle cry',\n",
              " 'Children shouting',\n",
              " 'Screaming',\n",
              " 'Whispering',\n",
              " 'Laughter',\n",
              " 'Baby laughter',\n",
              " 'Giggle',\n",
              " 'Snicker',\n",
              " 'Belly laugh',\n",
              " 'Chuckle, chortle',\n",
              " 'Crying, sobbing',\n",
              " 'Baby cry, infant cry',\n",
              " 'Whimper',\n",
              " 'Wail, moan',\n",
              " 'Sigh',\n",
              " 'Singing',\n",
              " 'Choir',\n",
              " 'Yodeling',\n",
              " 'Chant',\n",
              " 'Mantra',\n",
              " 'Male singing',\n",
              " 'Female singing',\n",
              " 'Child singing',\n",
              " 'Synthetic singing',\n",
              " 'Rapping',\n",
              " 'Humming',\n",
              " 'Groan',\n",
              " 'Grunt',\n",
              " 'Whistling',\n",
              " 'Breathing',\n",
              " 'Wheeze',\n",
              " 'Snoring',\n",
              " 'Gasp',\n",
              " 'Pant',\n",
              " 'Snort',\n",
              " 'Cough',\n",
              " 'Throat clearing',\n",
              " 'Sneeze',\n",
              " 'Sniff',\n",
              " 'Run',\n",
              " 'Shuffle',\n",
              " 'Walk, footsteps',\n",
              " 'Chewing, mastication',\n",
              " 'Biting',\n",
              " 'Gargling',\n",
              " 'Stomach rumble',\n",
              " 'Burping, eructation',\n",
              " 'Hiccup',\n",
              " 'Fart',\n",
              " 'Hands',\n",
              " 'Finger snapping',\n",
              " 'Clapping',\n",
              " 'Heart sounds, heartbeat',\n",
              " 'Heart murmur',\n",
              " 'Cheering',\n",
              " 'Applause',\n",
              " 'Chatter',\n",
              " 'Crowd',\n",
              " 'Hubbub, speech noise, speech babble',\n",
              " 'Children playing',\n",
              " 'Animal',\n",
              " 'Domestic animals, pets',\n",
              " 'Dog',\n",
              " 'Bark',\n",
              " 'Yip',\n",
              " 'Howl',\n",
              " 'Bow-wow',\n",
              " 'Growling',\n",
              " 'Whimper (dog)',\n",
              " 'Cat',\n",
              " 'Purr',\n",
              " 'Meow',\n",
              " 'Hiss',\n",
              " 'Caterwaul',\n",
              " 'Livestock, farm animals, working animals',\n",
              " 'Horse',\n",
              " 'Clip-clop',\n",
              " 'Neigh, whinny',\n",
              " 'Cattle, bovinae',\n",
              " 'Moo',\n",
              " 'Cowbell',\n",
              " 'Pig',\n",
              " 'Oink',\n",
              " 'Goat',\n",
              " 'Bleat',\n",
              " 'Sheep',\n",
              " 'Fowl',\n",
              " 'Chicken, rooster',\n",
              " 'Cluck',\n",
              " 'Crowing, cock-a-doodle-doo',\n",
              " 'Turkey',\n",
              " 'Gobble',\n",
              " 'Duck',\n",
              " 'Quack',\n",
              " 'Goose',\n",
              " 'Honk',\n",
              " 'Wild animals',\n",
              " 'Roaring cats (lions, tigers)',\n",
              " 'Roar',\n",
              " 'Bird',\n",
              " 'Bird vocalization, bird call, bird song',\n",
              " 'Chirp, tweet',\n",
              " 'Squawk',\n",
              " 'Pigeon, dove',\n",
              " 'Coo',\n",
              " 'Crow',\n",
              " 'Caw',\n",
              " 'Owl',\n",
              " 'Hoot',\n",
              " 'Bird flight, flapping wings',\n",
              " 'Canidae, dogs, wolves',\n",
              " 'Rodents, rats, mice',\n",
              " 'Mouse',\n",
              " 'Patter',\n",
              " 'Insect',\n",
              " 'Cricket',\n",
              " 'Mosquito',\n",
              " 'Fly, housefly',\n",
              " 'Buzz',\n",
              " 'Bee, wasp, etc.',\n",
              " 'Frog',\n",
              " 'Croak',\n",
              " 'Snake',\n",
              " 'Rattle',\n",
              " 'Whale vocalization',\n",
              " 'Music',\n",
              " 'Musical instrument',\n",
              " 'Plucked string instrument',\n",
              " 'Guitar',\n",
              " 'Electric guitar',\n",
              " 'Bass guitar',\n",
              " 'Acoustic guitar',\n",
              " 'Steel guitar, slide guitar',\n",
              " 'Tapping (guitar technique)',\n",
              " 'Strum',\n",
              " 'Banjo',\n",
              " 'Sitar',\n",
              " 'Mandolin',\n",
              " 'Zither',\n",
              " 'Ukulele',\n",
              " 'Keyboard (musical)',\n",
              " 'Piano',\n",
              " 'Electric piano',\n",
              " 'Organ',\n",
              " 'Electronic organ',\n",
              " 'Hammond organ',\n",
              " 'Synthesizer',\n",
              " 'Sampler',\n",
              " 'Harpsichord',\n",
              " 'Percussion',\n",
              " 'Drum kit',\n",
              " 'Drum machine',\n",
              " 'Drum',\n",
              " 'Snare drum',\n",
              " 'Rimshot',\n",
              " 'Drum roll',\n",
              " 'Bass drum',\n",
              " 'Timpani',\n",
              " 'Tabla',\n",
              " 'Cymbal',\n",
              " 'Hi-hat',\n",
              " 'Wood block',\n",
              " 'Tambourine',\n",
              " 'Rattle (instrument)',\n",
              " 'Maraca',\n",
              " 'Gong',\n",
              " 'Tubular bells',\n",
              " 'Mallet percussion',\n",
              " 'Marimba, xylophone',\n",
              " 'Glockenspiel',\n",
              " 'Vibraphone',\n",
              " 'Steelpan',\n",
              " 'Orchestra',\n",
              " 'Brass instrument',\n",
              " 'French horn',\n",
              " 'Trumpet',\n",
              " 'Trombone',\n",
              " 'Bowed string instrument',\n",
              " 'String section',\n",
              " 'Violin, fiddle',\n",
              " 'Pizzicato',\n",
              " 'Cello',\n",
              " 'Double bass',\n",
              " 'Wind instrument, woodwind instrument',\n",
              " 'Flute',\n",
              " 'Saxophone',\n",
              " 'Clarinet',\n",
              " 'Harp',\n",
              " 'Bell',\n",
              " 'Church bell',\n",
              " 'Jingle bell',\n",
              " 'Bicycle bell',\n",
              " 'Tuning fork',\n",
              " 'Chime',\n",
              " 'Wind chime',\n",
              " 'Change ringing (campanology)',\n",
              " 'Harmonica',\n",
              " 'Accordion',\n",
              " 'Bagpipes',\n",
              " 'Didgeridoo',\n",
              " 'Shofar',\n",
              " 'Theremin',\n",
              " 'Singing bowl',\n",
              " 'Scratching (performance technique)',\n",
              " 'Pop music',\n",
              " 'Hip hop music',\n",
              " 'Beatboxing',\n",
              " 'Rock music',\n",
              " 'Heavy metal',\n",
              " 'Punk rock',\n",
              " 'Grunge',\n",
              " 'Progressive rock',\n",
              " 'Rock and roll',\n",
              " 'Psychedelic rock',\n",
              " 'Rhythm and blues',\n",
              " 'Soul music',\n",
              " 'Reggae',\n",
              " 'Country',\n",
              " 'Swing music',\n",
              " 'Bluegrass',\n",
              " 'Funk',\n",
              " 'Folk music',\n",
              " 'Middle Eastern music',\n",
              " 'Jazz',\n",
              " 'Disco',\n",
              " 'Classical music',\n",
              " 'Opera',\n",
              " 'Electronic music',\n",
              " 'House music',\n",
              " 'Techno',\n",
              " 'Dubstep',\n",
              " 'Drum and bass',\n",
              " 'Electronica',\n",
              " 'Electronic dance music',\n",
              " 'Ambient music',\n",
              " 'Trance music',\n",
              " 'Music of Latin America',\n",
              " 'Salsa music',\n",
              " 'Flamenco',\n",
              " 'Blues',\n",
              " 'Music for children',\n",
              " 'New-age music',\n",
              " 'Vocal music',\n",
              " 'A capella',\n",
              " 'Music of Africa',\n",
              " 'Afrobeat',\n",
              " 'Christian music',\n",
              " 'Gospel music',\n",
              " 'Music of Asia',\n",
              " 'Carnatic music',\n",
              " 'Music of Bollywood',\n",
              " 'Ska',\n",
              " 'Traditional music',\n",
              " 'Independent music',\n",
              " 'Song',\n",
              " 'Background music',\n",
              " 'Theme music',\n",
              " 'Jingle (music)',\n",
              " 'Soundtrack music',\n",
              " 'Lullaby',\n",
              " 'Video game music',\n",
              " 'Christmas music',\n",
              " 'Dance music',\n",
              " 'Wedding music',\n",
              " 'Happy music',\n",
              " 'Funny music',\n",
              " 'Sad music',\n",
              " 'Tender music',\n",
              " 'Exciting music',\n",
              " 'Angry music',\n",
              " 'Scary music',\n",
              " 'Wind',\n",
              " 'Rustling leaves',\n",
              " 'Wind noise (microphone)',\n",
              " 'Thunderstorm',\n",
              " 'Thunder',\n",
              " 'Water',\n",
              " 'Rain',\n",
              " 'Raindrop',\n",
              " 'Rain on surface',\n",
              " 'Stream',\n",
              " 'Waterfall',\n",
              " 'Ocean',\n",
              " 'Waves, surf',\n",
              " 'Steam',\n",
              " 'Gurgling',\n",
              " 'Fire',\n",
              " 'Crackle',\n",
              " 'Vehicle',\n",
              " 'Boat, Water vehicle',\n",
              " 'Sailboat, sailing ship',\n",
              " 'Rowboat, canoe, kayak',\n",
              " 'Motorboat, speedboat',\n",
              " 'Ship',\n",
              " 'Motor vehicle (road)',\n",
              " 'Car',\n",
              " 'Vehicle horn, car horn, honking',\n",
              " 'Toot',\n",
              " 'Car alarm',\n",
              " 'Power windows, electric windows',\n",
              " 'Skidding',\n",
              " 'Tire squeal',\n",
              " 'Car passing by',\n",
              " 'Race car, auto racing',\n",
              " 'Truck',\n",
              " 'Air brake',\n",
              " 'Air horn, truck horn',\n",
              " 'Reversing beeps',\n",
              " 'Ice cream truck, ice cream van',\n",
              " 'Bus',\n",
              " 'Emergency vehicle',\n",
              " 'Police car (siren)',\n",
              " 'Ambulance (siren)',\n",
              " 'Fire engine, fire truck (siren)',\n",
              " 'Motorcycle',\n",
              " 'Traffic noise, roadway noise',\n",
              " 'Rail transport',\n",
              " 'Train',\n",
              " 'Train whistle',\n",
              " 'Train horn',\n",
              " 'Railroad car, train wagon',\n",
              " 'Train wheels squealing',\n",
              " 'Subway, metro, underground',\n",
              " 'Aircraft',\n",
              " 'Aircraft engine',\n",
              " 'Jet engine',\n",
              " 'Propeller, airscrew',\n",
              " 'Helicopter',\n",
              " 'Fixed-wing aircraft, airplane',\n",
              " 'Bicycle',\n",
              " 'Skateboard',\n",
              " 'Engine',\n",
              " 'Light engine (high frequency)',\n",
              " \"Dental drill, dentist's drill\",\n",
              " 'Lawn mower',\n",
              " 'Chainsaw',\n",
              " 'Medium engine (mid frequency)',\n",
              " 'Heavy engine (low frequency)',\n",
              " 'Engine knocking',\n",
              " 'Engine starting',\n",
              " 'Idling',\n",
              " 'Accelerating, revving, vroom',\n",
              " 'Door',\n",
              " 'Doorbell',\n",
              " 'Ding-dong',\n",
              " 'Sliding door',\n",
              " 'Slam',\n",
              " 'Knock',\n",
              " 'Tap',\n",
              " 'Squeak',\n",
              " 'Cupboard open or close',\n",
              " 'Drawer open or close',\n",
              " 'Dishes, pots, and pans',\n",
              " 'Cutlery, silverware',\n",
              " 'Chopping (food)',\n",
              " 'Frying (food)',\n",
              " 'Microwave oven',\n",
              " 'Blender',\n",
              " 'Water tap, faucet',\n",
              " 'Sink (filling or washing)',\n",
              " 'Bathtub (filling or washing)',\n",
              " 'Hair dryer',\n",
              " 'Toilet flush',\n",
              " 'Toothbrush',\n",
              " 'Electric toothbrush',\n",
              " 'Vacuum cleaner',\n",
              " 'Zipper (clothing)',\n",
              " 'Keys jangling',\n",
              " 'Coin (dropping)',\n",
              " 'Scissors',\n",
              " 'Electric shaver, electric razor',\n",
              " 'Shuffling cards',\n",
              " 'Typing',\n",
              " 'Typewriter',\n",
              " 'Computer keyboard',\n",
              " 'Writing',\n",
              " 'Alarm',\n",
              " 'Telephone',\n",
              " 'Telephone bell ringing',\n",
              " 'Ringtone',\n",
              " 'Telephone dialing, DTMF',\n",
              " 'Dial tone',\n",
              " 'Busy signal',\n",
              " 'Alarm clock',\n",
              " 'Siren',\n",
              " 'Civil defense siren',\n",
              " 'Buzzer',\n",
              " 'Smoke detector, smoke alarm',\n",
              " 'Fire alarm',\n",
              " 'Foghorn',\n",
              " 'Whistle',\n",
              " 'Steam whistle',\n",
              " 'Mechanisms',\n",
              " 'Ratchet, pawl',\n",
              " 'Clock',\n",
              " 'Tick',\n",
              " 'Tick-tock',\n",
              " 'Gears',\n",
              " 'Pulleys',\n",
              " 'Sewing machine',\n",
              " 'Mechanical fan',\n",
              " 'Air conditioning',\n",
              " 'Cash register',\n",
              " 'Printer',\n",
              " 'Camera',\n",
              " 'Single-lens reflex camera',\n",
              " 'Tools',\n",
              " 'Hammer',\n",
              " 'Jackhammer',\n",
              " 'Sawing',\n",
              " 'Filing (rasp)',\n",
              " 'Sanding',\n",
              " 'Power tool',\n",
              " 'Drill',\n",
              " 'Explosion',\n",
              " 'Gunshot, gunfire',\n",
              " 'Machine gun',\n",
              " 'Fusillade',\n",
              " 'Artillery fire',\n",
              " 'Cap gun',\n",
              " 'Fireworks',\n",
              " 'Firecracker',\n",
              " 'Burst, pop',\n",
              " 'Eruption',\n",
              " 'Boom',\n",
              " 'Wood',\n",
              " 'Chop',\n",
              " 'Splinter',\n",
              " 'Crack',\n",
              " 'Glass',\n",
              " 'Chink, clink',\n",
              " 'Shatter',\n",
              " 'Liquid',\n",
              " 'Splash, splatter',\n",
              " 'Slosh',\n",
              " 'Squish',\n",
              " 'Drip',\n",
              " 'Pour',\n",
              " 'Trickle, dribble',\n",
              " 'Gush',\n",
              " 'Fill (with liquid)',\n",
              " 'Spray',\n",
              " 'Pump (liquid)',\n",
              " 'Stir',\n",
              " 'Boiling',\n",
              " 'Sonar',\n",
              " 'Arrow',\n",
              " 'Whoosh, swoosh, swish',\n",
              " 'Thump, thud',\n",
              " 'Thunk',\n",
              " 'Electronic tuner',\n",
              " 'Effects unit',\n",
              " 'Chorus effect',\n",
              " 'Basketball bounce',\n",
              " 'Bang',\n",
              " 'Slap, smack',\n",
              " 'Whack, thwack',\n",
              " 'Smash, crash',\n",
              " 'Breaking',\n",
              " 'Bouncing',\n",
              " 'Whip',\n",
              " 'Flap',\n",
              " 'Scratch',\n",
              " 'Scrape',\n",
              " 'Rub',\n",
              " 'Roll',\n",
              " 'Crushing',\n",
              " 'Crumpling, crinkling',\n",
              " 'Tearing',\n",
              " 'Beep, bleep',\n",
              " 'Ping',\n",
              " 'Ding',\n",
              " 'Clang',\n",
              " 'Squeal',\n",
              " 'Creak',\n",
              " 'Rustle',\n",
              " 'Whir',\n",
              " 'Clatter',\n",
              " 'Sizzle',\n",
              " 'Clicking',\n",
              " 'Clickety-clack',\n",
              " 'Rumble',\n",
              " 'Plop',\n",
              " 'Jingle, tinkle',\n",
              " 'Hum',\n",
              " 'Zing',\n",
              " 'Boing',\n",
              " 'Crunch',\n",
              " 'Silence',\n",
              " 'Sine wave',\n",
              " 'Harmonic',\n",
              " 'Chirp tone',\n",
              " 'Sound effect',\n",
              " 'Pulse',\n",
              " 'Inside, small room',\n",
              " 'Inside, large room or hall',\n",
              " 'Inside, public space',\n",
              " 'Outside, urban or manmade',\n",
              " 'Outside, rural or natural',\n",
              " 'Reverberation',\n",
              " 'Echo',\n",
              " 'Noise',\n",
              " 'Environmental noise',\n",
              " 'Static',\n",
              " 'Mains hum',\n",
              " 'Distortion',\n",
              " 'Sidetone',\n",
              " 'Cacophony',\n",
              " 'White noise',\n",
              " 'Pink noise',\n",
              " 'Throbbing',\n",
              " 'Vibration',\n",
              " 'Television',\n",
              " 'Radio',\n",
              " 'Field recording']"
            ]
          },
          "execution_count": 7,
          "metadata": {},
          "output_type": "execute_result"
        }
      ],
      "source": [
        "class_labels_ast"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 8,
      "metadata": {
        "id": "v2WVqx3UiOPd"
      },
      "outputs": [],
      "source": [
        "esc50_to_audioset = {\n",
        "    \"dog\": \"Dog\",\n",
        "    \"rooster\": \"Rooster\",\n",
        "    \"pig\": \"Pig\",\n",
        "    \"cow\": \"Cattle\",\n",
        "    \"frog\": \"Frog\",\n",
        "    \"cat\": \"Meow\",\n",
        "    \"hen\": \"Chicken, rooster\",\n",
        "    \"insects\": \"Insect\",\n",
        "    \"sheep\": \"Sheep\",\n",
        "    \"crow\": \"Crow\",\n",
        "\n",
        "    \"rain\": \"Rain\",\n",
        "    \"sea_waves\": \"Ocean\",\n",
        "    \"crackling_fire\": \"Fire\",\n",
        "    \"crickets\": \"Cricket\",\n",
        "    \"chirping_birds\": \"Bird\",\n",
        "    \"water_drops\": \"Drip\",\n",
        "    \"wind\": \"Wind\",\n",
        "    \"pouring_water\": \"Pour\",\n",
        "    \"toilet_flush\": \"Toilet flush\",\n",
        "    \"thunderstorm\": \"Thunder\",\n",
        "\n",
        "    \"crying_baby\": \"Baby cry, infant cry\",\n",
        "    \"sneezing\": \"Sneeze\",\n",
        "    \"coughing\": \"Cough\",\n",
        "    \"snoring\": \"Snoring\",\n",
        "    \"breathing\": \"Breathing\",\n",
        "    \"footsteps\": \"Footsteps\",\n",
        "    \"laughing\": \"Laughter\",\n",
        "    \"brushing_teeth\": \"Toothbrush\",\n",
        "    \"drinking_sipping\": \"Drinking, sipping\",\n",
        "\n",
        "    \"door_wood_knock\": \"Knock\",\n",
        "    \"can_opening\": \"Can opening\",\n",
        "    \"washing_machine\": \"Washing machine\",\n",
        "    \"vacuum_cleaner\": \"Vacuum cleaner\",\n",
        "    \"clock_alarm\": \"Alarm\",\n",
        "    \"clock_tick\": \"Tick\",\n",
        "    \"glass_breaking\": \"Breaking\",\n",
        "    \"helicopter\": \"Helicopter\",\n",
        "    \"chainsaw\": \"Chainsaw\",\n",
        "    \"siren\": \"Siren\",\n",
        "\n",
        "    \"car_horn\": \"Car horn\",\n",
        "    \"engine\": \"Vehicle\",\n",
        "    \"train\": \"Train\",\n",
        "    \"church_bells\": \"Church bell\",\n",
        "    \"airplane\": \"Aircraft\",\n",
        "    \"fireworks\": \"Fireworks\",\n",
        "    \"hand_saw\": \"Sawing\",\n",
        "    \"keyboard_typing\": \"Typing\",\n",
        "    \"mouse_click\": \"Click\",\n",
        "    \"pen_click\": \"Click\",\n",
        "\n",
        "    \"writing\": \"Writing\",\n",
        "    \"snapping_fingers\": \"Finger snapping\",\n",
        "    \"clapping\": \"Applause\",\n",
        "    \"typing\": \"Typing\",\n",
        "    \"gargling\": \"Gargling\",\n",
        "    \"laughing\": \"Laughter\",\n",
        "    \"sighing\": \"Sigh\",\n",
        "    \"chewing\": \"Chewing, mastication\",\n",
        "    \"shuffling_cards\": \"Shuffling cards\",\n",
        "    \"stapler\": \"Stapler\"\n",
        "}\n",
        "\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 9,
      "metadata": {
        "id": "OACarOFI28Oe"
      },
      "outputs": [],
      "source": [
        "# Load label CSV\n",
        "label_df = pd.read_csv('/content/esc50.csv')\n",
        "\n",
        "# Create a dictionary to map filename -> true label (either category or target)\n",
        "true_labels = dict(zip(label_df['filename'], label_df['category']))\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 10,
      "metadata": {
        "id": "5U6DoUu93AiG"
      },
      "outputs": [],
      "source": [
        "import os\n",
        "wav_dir = '/content/Esc Song Folder'\n",
        "audio_files = [os.path.join(wav_dir, f) for f in os.listdir(wav_dir) if f.endswith('.wav')]\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 12,
      "metadata": {
        "id": "CRXIaJQKCJhB"
      },
      "outputs": [],
      "source": [
        "# Simple audio preprocessing with soundfile\n",
        "def load_audio(path):\n",
        "    try:\n",
        "        # Try soundfile first (faster and more reliable)\n",
        "        audio, sr = sf.read(path)\n",
        "\n",
        "        # Convert to mono if stereo\n",
        "        if len(audio.shape) > 1:\n",
        "            audio = np.mean(audio, axis=1)\n",
        "\n",
        "        # Resample to 16kHz if needed\n",
        "        if sr != 16000:\n",
        "            audio = librosa.resample(audio, orig_sr=sr, target_sr=16000)\n",
        "            sr = 16000\n",
        "\n",
        "        # Normalize\n",
        "        audio = audio / np.max(np.abs(audio))\n",
        "\n",
        "        return audio, sr\n",
        "\n",
        "    except Exception as e:\n",
        "        print(f\"Error loading {path}: {e}\")\n",
        "        # Fallback to librosa\n",
        "        audio, sr = librosa.load(path, sr=16000)\n",
        "        return librosa.util.normalize(audio), sr\n",
        "\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 14,
      "metadata": {
        "id": "QC5bdlSoCOsR"
      },
      "outputs": [],
      "source": [
        "# AST prediction\n",
        "def predict_ast(audio, sr):\n",
        "    inputs = ast_extractor(audio, sampling_rate=sr, return_tensors=\"pt\")\n",
        "    inputs = {k: v.to(device) for k, v in inputs.items()}\n",
        "    outputs = ast_model(**inputs)\n",
        "    return torch.nn.functional.softmax(outputs.logits, dim=-1).detach().cpu().numpy()"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 15,
      "metadata": {
        "id": "73xR-197CUpc"
      },
      "outputs": [],
      "source": [
        "# Wav2Vec2 prediction\n",
        "def predict_wav2vec(audio, sr):\n",
        "    inputs = wav2vec_extractor(audio, sampling_rate=sr, return_tensors=\"pt\", padding=True)\n",
        "    inputs = {k: v.to(device) for k, v in inputs.items()}\n",
        "    outputs = wav2vec_model(**inputs)\n",
        "    return torch.nn.functional.softmax(outputs.logits, dim=-1).detach().cpu().numpy()"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 16,
      "metadata": {
        "id": "S-tu_7wHCcBV"
      },
      "outputs": [],
      "source": [
        "# HuBERT prediction\n",
        "def predict_hubert(audio, sr):\n",
        "    inputs = hubert_extractor(audio, sampling_rate=sr, return_tensors=\"pt\")\n",
        "    inputs = {k: v.to(device) for k, v in inputs.items()}\n",
        "    outputs = hubert_model(**inputs)\n",
        "    return torch.nn.functional.softmax(outputs.logits, dim=-1).detach().cpu().numpy()\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 17,
      "metadata": {
        "id": "vM_HespTCg8Z"
      },
      "outputs": [],
      "source": [
        "def classify_audio(audio_path):\n",
        "    audio, sr = load_audio(audio_path)\n",
        "\n",
        "    pred_ast = predict_ast(audio, sr)\n",
        "\n",
        "    predicted_index = np.argmax(pred_ast)\n",
        "    predicted_class = class_labels_ast[predicted_index]\n",
        "    confidence = np.max(pred_ast)\n",
        "\n",
        "    return predicted_class, confidence, pred_ast\n",
        "\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 19,
      "metadata": {
        "id": "fKszbz_VO5ug"
      },
      "outputs": [],
      "source": [
        "# Alternative: Get predictions from all models separately\n",
        "def classify_audio_all_models(audio_path):\n",
        "    audio, sr = load_audio(audio_path)\n",
        "\n",
        "    pred_ast = predict_ast(audio, sr)\n",
        "    pred_wav2vec = predict_wav2vec(audio, sr)\n",
        "    pred_hubert = predict_hubert(audio, sr)\n",
        "\n",
        "    # Return results from each model\n",
        "    results = {\n",
        "        'ast': {'class': np.argmax(pred_ast), 'confidence': np.max(pred_ast), 'probs': pred_ast},\n",
        "        'wav2vec': {'class': np.argmax(pred_wav2vec), 'confidence': np.max(pred_wav2vec), 'probs': pred_wav2vec},\n",
        "        'hubert': {'class': np.argmax(pred_hubert), 'confidence': np.max(pred_hubert), 'probs': pred_hubert}\n",
        "    }\n",
        "\n",
        "    return results\n",
        "\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 20,
      "metadata": {
        "id": "Ptx0xsARCnoz"
      },
      "outputs": [],
      "source": [
        "# Batch processing\n",
        "def classify_batch(audio_files):\n",
        "    results = []\n",
        "    for file in audio_files:\n",
        "        try:\n",
        "            predicted_class, confidence, _ = classify_audio(file)\n",
        "            results.append({\n",
        "                'file': os.path.basename(file),\n",
        "                'class': predicted_class,\n",
        "                'confidence': confidence\n",
        "            })\n",
        "        except Exception as e:\n",
        "            print(f\"Error processing {file}: {e}\")\n",
        "    return results\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "ZzA77ZnY3XnN"
      },
      "outputs": [],
      "source": []
    },
    {
      "cell_type": "code",
      "execution_count": 23,
      "metadata": {
        "id": "m425UccyqzDd"
      },
      "outputs": [],
      "source": [
        "def extract_features(audio, sr):\n",
        "    mfcc = np.mean(librosa.feature.mfcc(y=audio, sr=sr, n_mfcc=40), axis=1)\n",
        "    chroma = np.mean(librosa.feature.chroma_stft(y=audio, sr=sr), axis=1)\n",
        "    spectral_centroid = np.mean(librosa.feature.spectral_centroid(y=audio, sr=sr), axis=1)\n",
        "    spectral_rolloff = np.mean(librosa.feature.spectral_rolloff(y=audio, sr=sr), axis=1)\n",
        "    zero_crossing = np.mean(librosa.feature.zero_crossing_rate(audio), axis=1)\n",
        "    rmse = np.mean(librosa.feature.rms(y=audio), axis=1)\n",
        "    tempo = librosa.beat.tempo(y=audio, sr=sr)\n",
        "\n",
        "    return np.concatenate([mfcc, chroma, spectral_centroid, spectral_rolloff, zero_crossing, rmse, [tempo[0]]])\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 24,
      "metadata": {
        "id": "CqGW39OKu8vi"
      },
      "outputs": [],
      "source": [
        "def get_top_k_predictions(probs, k=3):\n",
        "    topk_indices = np.argsort(probs[0])[::-1][:k]\n",
        "    topk_labels = [class_labels_ast[i] for i in topk_indices]\n",
        "    topk_confidences = [probs[0][i] for i in topk_indices]\n",
        "    return list(zip(topk_labels, topk_confidences))\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 25,
      "metadata": {
        "id": "V8aCT2q4vHY1"
      },
      "outputs": [],
      "source": [
        "# Evaluate Top-K Accuracy\n",
        "def evaluate_top_k(results, k=3):\n",
        "    correct = 0\n",
        "    total = 0\n",
        "\n",
        "    for result in results:\n",
        "        file = result['file']\n",
        "        audio_path = os.path.join(wav_dir, file)\n",
        "        audio, sr = load_audio(audio_path)\n",
        "\n",
        "        probs = predict_ast(audio, sr)\n",
        "        topk = get_top_k_predictions(probs, k)\n",
        "\n",
        "        true_label = true_labels.get(file)\n",
        "        mapped_label = esc50_to_audioset.get(true_label)\n",
        "\n",
        "        match = any(pred == mapped_label for pred, conf in topk)\n",
        "\n",
        "        if match:\n",
        "            correct += 1\n",
        "        total += 1\n",
        "\n",
        "        print(f\"File: {file}, True: {true_label} -> {mapped_label}, Top-{k}: {[p for p, _ in topk]}, Match: {match}\")\n",
        "\n",
        "    accuracy = correct / total if total > 0 else 0\n",
        "    print(f\"\\nTop-{k} Accuracy (Mapped): {accuracy:.4f}\")\n",
        "    return accuracy\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 26,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "lwFQ9BElCzRC",
        "outputId": "4f071ec4-eedf-4c1b-a8dd-e49dc32a7b95"
      },
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Downloaded to sample.wav\n"
          ]
        }
      ],
      "source": [
        "import urllib.request\n",
        "\n",
        "# A valid .wav file (simple piano note) from GitHub\n",
        "url = \"https://raw.githubusercontent.com/Jakobovski/free-spoken-digit-dataset/master/recordings/0_george_0.wav\"\n",
        "output_file = \"sample.wav\"\n",
        "\n",
        "urllib.request.urlretrieve(url, output_file)\n",
        "print(f\"Downloaded to {output_file}\")\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 27,
      "metadata": {
        "id": "6a2ebf7d"
      },
      "outputs": [],
      "source": [
        "# Generate a test audio signal\n",
        "def create_test_audio():\n",
        "    import numpy as np\n",
        "    import scipy.io.wavfile as wav\n",
        "\n",
        "    # Create a simple test tone\n",
        "    sample_rate = 16000\n",
        "    duration = 3  # seconds\n",
        "    frequency = 440  # Hz\n",
        "\n",
        "    t = np.linspace(0, duration, int(sample_rate * duration))\n",
        "    audio_signal = np.sin(2 * np.pi * frequency * t)\n",
        "\n",
        "    # Save as WAV file\n",
        "    wav.write(\"test_audio.wav\", sample_rate, audio_signal.astype(np.float32))\n",
        "    return \"test_audio.wav\"\n",
        "\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 28,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "oktqrCJQVFAb",
        "outputId": "686717ed-7f6e-4de6-8544-d9adf8131102"
      },
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Created test file: test_audio.wav\n"
          ]
        }
      ],
      "source": [
        "# Create and test with generated audio\n",
        "test_file = create_test_audio()\n",
        "print(f\"Created test file: {test_file}\")"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 29,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "3QLmfiNZVFD4",
        "outputId": "b2295334-2a34-4e27-b08d-22b00a7d86d7"
      },
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Test Audio - Predicted Class: Sine wave, Confidence: 0.9805\n"
          ]
        }
      ],
      "source": [
        "# Test with the generated file\n",
        "predicted_class, confidence, _ = classify_audio(test_file)\n",
        "print(f\"Test Audio - Predicted Class: {predicted_class}, Confidence: {confidence:.4f}\")\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 30,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "rjTQrdOumXZS",
        "outputId": "70bd6c17-754b-4da7-a6c2-c84180a0c661"
      },
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Predicted Class: Speech, Confidence: 0.8292\n"
          ]
        }
      ],
      "source": [
        "predicted_class, confidence, _ = classify_audio(output_file)\n",
        "print(f\"Predicted Class: {predicted_class}, Confidence: {confidence:.4f}\")"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 31,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "6uwRr_kmVPK-",
        "outputId": "d299e2be-46eb-4372-9095-540663829edd"
      },
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "AST: Class 0, Confidence: 0.8292\n",
            "Wav2Vec: Class 0, Confidence: 0.5046\n",
            "HuBERT: Class 0, Confidence: 0.5016\n"
          ]
        }
      ],
      "source": [
        "# Get predictions from all models separately\n",
        "all_results = classify_audio_all_models(output_file)\n",
        "print(f\"AST: Class {all_results['ast']['class']}, Confidence: {all_results['ast']['confidence']:.4f}\")\n",
        "print(f\"Wav2Vec: Class {all_results['wav2vec']['class']}, Confidence: {all_results['wav2vec']['confidence']:.4f}\")\n",
        "print(f\"HuBERT: Class {all_results['hubert']['class']}, Confidence: {all_results['hubert']['confidence']:.4f}\")\n"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "o_x42luk3ttB"
      },
      "source": [
        "- using 20 audios for batch classification using all audios takes lots of time."
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 32,
      "metadata": {
        "id": "DarDizYE3a_D"
      },
      "outputs": [],
      "source": [
        "results = classify_batch(audio_files)\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 33,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "fQYCInzjVPRO",
        "outputId": "277dee63-a37b-43cf-c5bd-cfe96fff5aeb"
      },
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Feature vector shape: (57,)\n"
          ]
        }
      ],
      "source": [
        "# Extract features for custom training\n",
        "\n",
        "try:\n",
        "    audio, sr = load_audio(output_file)\n",
        "    features = extract_features(audio, sr)\n",
        "    print(f\"Feature vector shape: {features.shape}\")\n",
        "except NameError:\n",
        "    print(\"Please make sure 'audio_file' and 'load_audio' are defined by running previous cells.\")\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 35,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "DDqVl4Pk339Q",
        "outputId": "eff21095-e814-4a5e-f1b3-6b79ed0744aa"
      },
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "File: 5-257642-A-39.wav, True: glass_breaking -> Breaking, Top-4: ['Breaking', 'Glass', 'Chink, clink', 'Shatter'], Match: True\n",
            "File: 5-259640-A-29.wav, True: drinking_sipping -> Drinking, sipping, Top-4: ['Speech', 'Whimper', 'Throat clearing', 'Sneeze'], Match: False\n",
            "File: 5-254160-A-22.wav, True: clapping -> Applause, Top-4: ['Applause', 'Speech', 'Male speech, man speaking', 'Clapping'], Match: True\n",
            "File: 5-254832-A-15.wav, True: water_drops -> Drip, Top-4: ['Finger snapping', 'Ping', 'Sound effect', 'Music'], Match: False\n",
            "File: 5-61635-A-8.wav, True: sheep -> Sheep, Top-4: ['Sheep', 'Bleat', 'Animal', 'Livestock, farm animals, working animals'], Match: True\n",
            "File: 5-259180-A-15.wav, True: water_drops -> Drip, Top-4: ['Plop', 'Drip', 'Liquid', 'Speech'], Match: True\n",
            "File: 5-259169-A-5.wav, True: cat -> Meow, Top-4: ['Screaming', 'Meow', 'Speech', 'Domestic animals, pets'], Match: True\n",
            "File: 5-9032-A-0.wav, True: dog -> Dog, Top-4: ['Domestic animals, pets', 'Squeak', 'Animal', 'Dog'], Match: True\n",
            "File: 5-260164-A-23.wav, True: breathing -> Breathing, Top-4: ['Snort', 'Gasp', 'Breathing', 'Sound effect'], Match: True\n",
            "File: 5-256452-A-5.wav, True: cat -> Meow, Top-4: ['Meow', 'Cat', 'Domestic animals, pets', 'Animal'], Match: True\n",
            "File: 5-260011-A-34.wav, True: can_opening -> Can opening, Top-4: ['Coin (dropping)', 'Silence', 'Crack', 'Scissors'], Match: False\n",
            "File: 5-253534-A-26.wav, True: laughing -> Laughter, Top-4: ['Laughter', 'Snicker', 'Giggle', 'Baby laughter'], Match: True\n",
            "File: 5-257349-A-15.wav, True: water_drops -> Drip, Top-4: ['Sound effect', 'Drip', 'Crunch', 'Biting'], Match: True\n",
            "File: 5-253101-C-49.wav, True: hand_saw -> Sawing, Top-4: ['Sawing', 'Wood', 'Rub', 'Tools'], Match: True\n",
            "File: 5-254832-B-15.wav, True: water_drops -> Drip, Top-4: ['Ping', 'Finger snapping', 'Tick', 'Tick-tock'], Match: False\n",
            "File: 5-256512-A-30.wav, True: door_wood_knock -> Knock, Top-4: ['Knock', 'Music', 'Hammer', 'Thunk'], Match: True\n",
            "File: 5-253101-B-49.wav, True: hand_saw -> Sawing, Top-4: ['Sawing', 'Wood', 'Rub', 'Filing (rasp)'], Match: True\n",
            "File: 5-260432-A-39.wav, True: glass_breaking -> Breaking, Top-4: ['Chink, clink', 'Coin (dropping)', 'Breaking', 'Glass'], Match: True\n",
            "File: 5-257839-A-14.wav, True: chirping_birds -> Bird, Top-4: ['Bird', 'Bird vocalization, bird call, bird song', 'Chirp, tweet', 'Squawk'], Match: True\n",
            "File: 5-259514-A-26.wav, True: laughing -> Laughter, Top-4: ['Fowl', 'Wheeze', 'Chicken, rooster', 'Animal'], Match: False\n",
            "File: 5-51149-A-25.wav, True: footsteps -> Footsteps, Top-4: ['Knock', 'Door', 'Thunk', 'Slam'], Match: False\n",
            "\n",
            "Top-4 Accuracy (Mapped): 0.7143\n"
          ]
        },
        {
          "data": {
            "text/plain": [
              "0.7142857142857143"
            ]
          },
          "execution_count": 35,
          "metadata": {},
          "output_type": "execute_result"
        }
      ],
      "source": [
        "evaluate_top_k(results, k=4)\n"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "0s6wZjAC1kD6"
      },
      "source": [
        "- Used three pretrained models: AST, Wav2Vec2, and HuBERT.\n",
        "\n",
        "- AST achieved Top-4 Accuracy of 71.4% (mapped with AudioSet labels).\n",
        "\n",
        "- AST performed best for environmental sound classification.\n",
        "\n",
        "- Wav2Vec2 and HuBERT also gave consistent predictions.\n",
        "\n",
        "- Pretrained models reduced training time and boosted performance.\n",
        "\n",
        "- Project shows effectiveness of transfer learning in audio tasks.\n",
        "\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "mOUwHOO534JP"
      },
      "outputs": [],
      "source": []
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "PwYeUgmTVPW0"
      },
      "outputs": [],
      "source": []
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "vFN8PKUNqoft"
      },
      "outputs": [],
      "source": []
    }
  ],
  "metadata": {
    "colab": {
      "provenance": []
    },
    "kernelspec": {
      "display_name": "base",
      "language": "python",
      "name": "python3"
    },
    "language_info": {
      "codemirror_mode": {
        "name": "ipython",
        "version": 3
      },
      "file_extension": ".py",
      "mimetype": "text/x-python",
      "name": "python",
      "nbconvert_exporter": "python",
      "pygments_lexer": "ipython3",
      "version": "3.11.7"
    }
  },
  "nbformat": 4,
  "nbformat_minor": 0
}
